发音器官 可视 语音 合成 系统 本发明 提供 了 一种 发音器官 可视 语音 合成 系统 ， 包括 ： 音频 分析 模块 、 参数 映射 模块 、 动画 驱动 模块 和 运动 分析 模块 ， 其中 ： 音频 分析 模块 ， 用于 接收 输入 的 说话 人 语音 信号 ， 根据 能量 信息 判断 静音 段 ， 将 非 静音 段 语音 进行 编码 ， 输出 语音 线谱 对 参数 ； 参数 映射 模块 ， 用于 接收 音频 分析 模块 实时 传递 来 的 语音 线谱 对 参数 ， 并 利用 经过训练 的 混合 高斯 模型 ， 将 其 转化 为 模型 运动 参数 ； 动画 驱动 模块 ， 用于 接收 参数 映射 模块 实时 生成 的 模型 运动 参数 ， 驱动 虚拟 发音器官 模型 的 关键点 运动 ， 进而 带动 整个 虚拟 发音器官 模型 的 运动 。 本发明 直接 由 输入 语音 的 频域 参数 生成 相应 的 运动 参数 来 带动 模型 运动 ， 具有 不 受 在线 数据库 的 限制 和 生理 模型 的 限制 优点 。 
